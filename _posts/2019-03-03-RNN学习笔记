---
layout: post
title: RNN学习笔记
date: 2019-03-09
--- 

# 简介 
RNN主要是为了解决序列问题而产生的，可以应用于很多与序列有关的场景，如语音识别、机器翻译、视频标注、自动问答、图片描述等，可以说是非常强大了。
# RNN结构类型
## 序列分类(N21)
- 输入是一个序列，输出是一个单独的值而不是序列，这种结构通常用来处理序列分类问题。如输入一段文字判别它所属的类别，输入一个句子判断其情感倾向，输入一段视频并判断它的类别等等。 
- 可以对最后一个 h 进行输出变换，或对所有的 h 进行平均后再进行输出变换
  ![](/assets/images/N21.jpg) 
## 文本生成(12N)
- 从图像生成文字（image caption），此时输入的X就是图像的特征，而输出的y序列就是一段句子;从类别生成语音或音乐;从关键字生成文章等
- 只在序列开始进行输入计算，其它 time step 输入为 0 
  ![](/assets/images/12N_0.png) 
- 把输入信息X作为每个阶段的输入  
  ![](/assets/images/12N_1.png)  
## 同步的序列到序列的模式(N2N)
- 最经典RNN结构要求输入和输出序列必须要是等长的。
- 由于这个限制的存在，经典RNN的适用范围比较小，但也有一些问题适合用经典的RNN结构建模，如：计算视频中每一帧的分类标签。因为要对每一帧进行计算，因此输入和输出序列等长。 
  ![](/assets/images/N2N.png)  
## 异步的序列到序列的模式(N2M)
- 这种 N vs M 的结构又叫 Encoder-Decoder 模型，也可称之为 Seq2Seq 模型。原始的 N vs N RNN 要求序列等长，然而我们遇到的大部分问题序列都是不等长的，如机器翻译中，源语言和目标语言的句子往往并没有相同的长度。Encoder-Decoder 模型可以有效的建模输入序列和输出序列不等长的问题，具体步骤如下：  
  - 首先，用一个 Encoder（RNN） 将输入的序列编码为一个上下文向量c。得到c有多种方式，最简单的方法就是把Encoder的最后一个隐状态赋值给c，还可以对最后的隐状态做一个变换得到c，也可以对所有的隐状态做变换得到c。 
    ![](/assets/images/N2M_1.png)   
  - 然后，用一个 Decoder（另一个RNN） 对 c 进行解码，将其变成输出序列。可以将 c 当做之前的初始状态 h0 输入到Decoder，也可以将 c 当做每一步的输入。 
    ![](/assets/images/N2M_2.png)    
    ![](/assets/images/N2M_3.png)   
