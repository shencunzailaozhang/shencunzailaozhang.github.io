---
layout: post
title: RNN学习笔记
date: 2019-03-09
--- 

# 简介 
RNN主要是为了解决序列问题而产生的，可以应用于很多与序列有关的场景，如语音识别、机器翻译、视频标注、自动问答、图片描述等，可以说是非常强大了。
# RNN结构类型
## 序列分类(N21)
- 输入是一个序列，输出是一个单独的值而不是序列，这种结构通常用来处理序列分类问题。如输入一段文字判别它所属的类别，输入一个句子判断其情感倾向，输入一段视频并判断它的类别等等。 
- 可以对最后一个 h 进行输出变换，或对所有的 h 进行平均后再进行输出变换
  ![](/assets/images/N21.jpg) 
## 文本生成(12N)
- 从图像生成文字（image caption），此时输入的X就是图像的特征，而输出的y序列就是一段句子;从类别生成语音或音乐;从关键字生成文章等
- 只在序列开始进行输入计算，其它 time step 输入为 0 
  ![](/assets/images/12N_0.png) 
- 把输入信息X作为每个阶段的输入  
  ![](/assets/images/12N_1.png)  
## 同步的序列到序列的模式(N2N)
- 最经典RNN结构要求输入和输出序列必须要是等长的。
- 由于这个限制的存在，经典RNN的适用范围比较小，但也有一些问题适合用经典的RNN结构建模，如：计算视频中每一帧的分类标签。因为要对每一帧进行计算，因此输入和输出序列等长。 
  ![](/assets/images/N2N.png)  
## 异步的序列到序列的模式(N2M)
- 这种 N vs M 的结构又叫 Encoder-Decoder 模型，也可称之为 Seq2Seq 模型。原始的 N vs N RNN 要求序列等长，然而我们遇到的大部分问题序列都是不等长的，如机器翻译中，源语言和目标语言的句子往往并没有相同的长度。Encoder-Decoder 模型可以有效的建模输入序列和输出序列不等长的问题，具体步骤如下：  
  - 首先，用一个 Encoder（RNN） 将输入的序列编码为一个上下文向量c。得到c有多种方式，最简单的方法就是把Encoder的最后一个隐状态赋值给c，还可以对最后的隐状态做一个变换得到c，也可以对所有的隐状态做变换得到c。 
![](/assets/images/N2M_1.png)   
  - 然后，用一个 Decoder（另一个RNN） 对 c 进行解码，将其变成输出序列。可以将 c 当做之前的初始状态 h0 输入到Decoder，也可以将 c 当做每一步的输入。 
![](/assets/images/N2M_2.png)    
![](/assets/images/N2M_3.png)   
# RNN公式
## 原始RNN 
### 结构及公式
![](/assets/images/RNN_structure1.jpg)  
可以展开成这样  
![](/assets/images/RNN_structure2.jpg)   
这个网络在t时刻接收到输入Xt之后，隐藏层的值是St，输出值是ot。关键一点是，st的值不仅仅取决于Xt，还取决于St−1。我们可以使用下面的公式来表示循环神经网络的计算方法：(f一般为tanh函数，g一般为softmax函数) 
![](/assets/images/RNN_gongshi1.png)   
## RNN常用变体————LSTM 
### 结构及公式  
![](/assets/images/LSTM_describe1.PNG)  
![](/assets/images/LSTM_structure.png)  
![](/assets/images/LSTM_describe2.PNG)   
### LSTM的变体————GRU
![](/assets/images/GRU_describe.PNG)  
![](/assets/images/GRU.png)  
# 注意力机制 
因为要解决序列问题，产生了RNN，但RNN也有其自身的缺陷————反向传播计算梯度时可能会出现[梯度消失或爆炸](https://zhuanlan.zhihu.com/p/28687529)的情况，为了解决这个问题，产生了LSTM，LSTM通过三个门决定要忘掉多少历史信息，存储多少新信息，但LSTM也有自己的[局限性](https://blog.csdn.net/songbinxu/article/details/80739447)————它对encoder中所有时刻隐层输出都采取同样的操作，然后输入到decoder中，这样没有侧重，所以注意力机制应运而生。 
![](/assets/images/attention_describe.PNG)  
![](/assets/images/attention.jpg)   
但即便如此，注意力机制还是可以进行改进，因为它没法保证C(word)中h(word)的权重最大，所以改进如下（我的手稿）：
![](/assets/images/manuscript.jpg)   

